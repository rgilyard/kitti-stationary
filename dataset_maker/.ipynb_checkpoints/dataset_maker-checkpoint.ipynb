{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deebde95-4cf5-4d87-a48d-160dbfd87f48",
   "metadata": {},
   "source": [
    "Stationary Dataset Creation\n",
    "from the KITTI dataset\n",
    "In my data folder, there are other folders from the KITTI dataset.\n",
    "Each of those folders is of a sequence. For each sequence, there is a folder for\n",
    "- image_00: black and white images from camera 1\n",
    "- image_01: black and white images from camera 2\n",
    "- image_02: color images from camera 1\n",
    "- image_03: color images from camera 2\n",
    "- oxts: Oxford Technical Solutions - the gps and positional data for the vehicle.\n",
    "- velodyne_points: the lidar frames from the sequence\n",
    "- tracklet_labels.xml: the labels for the lidar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ef0628-9dee-471b-b118-64fca68bbc0a",
   "metadata": {},
   "source": [
    "What I would like to end up with:\n",
    "- The data in kitti format. Images, lidar frames, labels, and camera images\n",
    "(by the way, I would have the calibration data for this)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733dcaf1-c245-4aef-9456-7b3fc36423f8",
   "metadata": {},
   "source": [
    "Intermediate data:\n",
    "- for each sequence folder, I would like to make a folder for each stationary sequence.\n",
    "- Each one of those folders contains \n",
    "    - a set of images, starting from 00000000.\n",
    "    - a set of corresponding original lidar frames\n",
    "    - a set of filtered lidar frames\n",
    "    - (later) a set of labeled points frames\n",
    "    - corresponding labels for each frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8478f7af-69a6-4bd0-9603-64d0e10dc3bf",
   "metadata": {},
   "source": [
    "To do list to get to the intermediate data\n",
    "For each of the folders in the original data:\n",
    "1. Get the stationary sequences\n",
    "2. Create folders for each stationary sequence\n",
    "   The folders can be the name of the original folder, plus the included frames\n",
    "    - images\n",
    "    - lidar_original\n",
    "    - lidar_filtered\n",
    "    - lidar_labeled_points\n",
    "    - labels\n",
    "3. For each stationary sequence, copy over the images (reindexing so the first one is 000000)\n",
    "4. Also copy over the corresponding original lidar frames.\n",
    "5. Filter the lidar frames and copy the filtered frames over.\n",
    "6. Convert the .xml files to label frames.\n",
    "7. Move the frame labels over.\n",
    "8. Extract the labeled points, and copy those frames over."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96742215-7b02-4f96-9727-d94550ab1e05",
   "metadata": {},
   "source": [
    "## Get stationary sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ac328f1-f056-4fea-8667-097d16daebe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b013654f-f4fe-42eb-89bd-9ab876646a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIRECTORY = '../data/'\n",
    "DATA_DIRECTORY_EXTENSION = '/oxts/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7a924a3-2780-4451-b2ae-1580b149482b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_data_from_dir(directory):\n",
    "    directory = directory + DATA_DIRECTORY_EXTENSION\n",
    "    data = []\n",
    "    # Loop through each file in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.txt'):\n",
    "            # Extract the numeric part of the filename and convert it to integer\n",
    "            file_index = int(filename.split('.')[0])  # Removes the extension and converts to int\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            with open(filepath, 'r') as file:\n",
    "                values = file.read().strip().split()\n",
    "                values = [float(value) for value in values]  # Convert each value to float\n",
    "                data.append([file_index] + values)  # Add file index and values to data list\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d32d800-4381-4b9b-a35b-c8c0669d3335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COLUMNS = [\n",
    "    'file_index', 'lat', 'lon', 'alt', 'roll', 'pitch', 'yaw', \n",
    "    'vn', 've', 'vf', 'vl', 'vu', 'ax', 'ay', 'az', 'af', \n",
    "    'al', 'au', 'wx', 'wy', 'wz', 'wf', 'wl', 'wu', \n",
    "    'pos_accuracy', 'vel_accuracy', 'navstat', 'numsats', \n",
    "    'posmode', 'velmode', 'orimode'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f77b1679-f00c-49b3-8b8c-56a099119b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify stationary frames\n",
    "VELOCITY_COLUMNS = ['vn', 've', 'vf', 'vl', 'vu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aba5131-1233-462d-b3a4-dde3bad3ea4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "STATIONARY_THRESHOLD = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7ce39979-ecfd-46df-af0c-4890de125b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sequences(df):\n",
    "    # Boolean series to identify stationary frames\n",
    "    is_stationary = df[VELOCITY_COLUMNS].abs().max(axis=1) < STATIONARY_THRESHOLD\n",
    "    # Find sequences of consecutive stationary frames\n",
    "    sequences = []\n",
    "    current_sequence = []\n",
    "    for i in df[is_stationary].index:\n",
    "        if current_sequence and i == current_sequence[-1] + 1:\n",
    "            current_sequence.append(i)\n",
    "        else:\n",
    "            if current_sequence:\n",
    "                sequences.append((current_sequence[0], current_sequence[-1]))\n",
    "            current_sequence = [i]\n",
    "\n",
    "    # Append the last sequence if it ended at the last index\n",
    "    if current_sequence:\n",
    "        sequences.append((current_sequence[0], current_sequence[-1]))\n",
    "    \n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7f7a4f7-11e2-4389-9856-b4bcd7258e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_one_folder(directory):\n",
    "    print(directory)\n",
    "    # Load data\n",
    "    data = get_data_from_dir(directory)\n",
    "    df = pd.DataFrame(data, columns=COLUMNS)\n",
    "    # Set 'file_index' as the index of the DataFrame\n",
    "    df.set_index('file_index', inplace=True)\n",
    "    df.sort_index(inplace=True)  # Ensure the DataFrame is sorted by index\n",
    "    \n",
    "    sequences = get_sequences(df)\n",
    "    \n",
    "    # Print the sequences\n",
    "    if sequences:\n",
    "        for start, end in sequences:\n",
    "            print(f\"Stationary sequence from frame {start} to frame {end}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0a42865-70b1-4637-99d4-d64f5600b04c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For each folder in the data directory\n",
    "def process_all_data_folders(directory):\n",
    "    # Loop through each item in the directory\n",
    "    for item in os.listdir(directory):\n",
    "        item_path = os.path.join(directory, item)\n",
    "        # Check if the item is a directory\n",
    "        if os.path.isdir(item_path):\n",
    "            # Process the data in the folder\n",
    "            process_one_folder(item_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d228a9d3-8cca-4fc5-9d61-83f4ce506148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/2011_09_26_drive_0017_sync\n",
      "file_index\n",
      "0      True\n",
      "1      True\n",
      "2      True\n",
      "3      True\n",
      "4      True\n",
      "       ... \n",
      "109    True\n",
      "110    True\n",
      "111    True\n",
      "112    True\n",
      "113    True\n",
      "Length: 114, dtype: bool\n",
      "\n",
      "../data/2011_09_26_drive_0018_sync\n",
      "file_index\n",
      "0       True\n",
      "1       True\n",
      "2       True\n",
      "3       True\n",
      "4       True\n",
      "       ...  \n",
      "265    False\n",
      "266    False\n",
      "267    False\n",
      "268    False\n",
      "269    False\n",
      "Length: 270, dtype: bool\n",
      "\n",
      "../data/2011_09_26_drive_0051_sync\n",
      "file_index\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "433    False\n",
      "434    False\n",
      "435    False\n",
      "436    False\n",
      "437    False\n",
      "Length: 438, dtype: bool\n",
      "\n",
      "../data/2011_09_26_drive_0060_sync\n",
      "file_index\n",
      "0     True\n",
      "1     True\n",
      "2     True\n",
      "3     True\n",
      "4     True\n",
      "      ... \n",
      "73    True\n",
      "74    True\n",
      "75    True\n",
      "76    True\n",
      "77    True\n",
      "Length: 78, dtype: bool\n",
      "\n",
      "../data/2011_09_26_drive_0001_sync\n",
      "file_index\n",
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "103    False\n",
      "104    False\n",
      "105    False\n",
      "106    False\n",
      "107    False\n",
      "Length: 108, dtype: bool\n",
      "\n",
      "../data/2011_09_26_drive_0002_sync\n",
      "file_index\n",
      "0     False\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4     False\n",
      "      ...  \n",
      "72    False\n",
      "73    False\n",
      "74    False\n",
      "75    False\n",
      "76    False\n",
      "Length: 77, dtype: bool\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_all_data_folders(DATA_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb603af-bf35-4c9d-98af-4c558cc90056",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "994c17b5-91d5-4348-ad0a-c5ae019707af",
   "metadata": {},
   "source": [
    "To do list to get from intermediate to kitti format\n",
    "- Go through each folder, keeping track of current index\n",
    "- move/copy all frame sets to the kitti format while reindexing\n",
    "- There will be 3 kitti sets, one each for stationary, filtered, and labeled points\n",
    "- Should the test/train split be the same?\n",
    "- also, perhaps also have three folders for just running inference and testing with the nuscenes model on kitti data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
