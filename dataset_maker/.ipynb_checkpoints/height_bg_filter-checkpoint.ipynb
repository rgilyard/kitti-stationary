{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e7e623-3db1-47b0-a2a9-dd076b04be2b",
   "metadata": {},
   "source": [
    "# Filter each stationary frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a689bb4-b129-40f6-a07a-2c94e6604124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import itertools\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bd788e-d8f5-4621-84a5-764b6f1f59ff",
   "metadata": {},
   "source": [
    "## Constants and such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f77dba0c-506d-41f7-94e0-1f78bd80b165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set background map resolutions\n",
    "azimuth_resolution = 0.1\n",
    "elevation_resolution = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73db7eb6-b3f9-4a18-b7bd-a7d6d7515511",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_ROOT = '../stationary_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af74dafa-7133-428b-8799-dbe0d7d67127",
   "metadata": {},
   "source": [
    "## First, functions for making background map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b0b2769-48b9-4b86-a127-a6ac5089a830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings for azimuth and height using integers\n",
    "def create_mappings(azimuth_step=azimuth_resolution, elevation_step=elevation_resolution):\n",
    "    # Create ranges and multiply by 10 to convert to integers\n",
    "    azimuth_range = np.arange(-180, 180 + azimuth_step, azimuth_step) * 10\n",
    "    elevation_range = np.arange(-30, 10 + elevation_step, elevation_step) * 10\n",
    "    \n",
    "    # Convert to integers and create dictionaries to map azimuth/height to index\n",
    "    azimuth_map = {int(az): idx for idx, az in enumerate(azimuth_range)}\n",
    "    elevation_map = {int(ht): idx for idx, ht in enumerate(elevation_range)}\n",
    "    return azimuth_map, elevation_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "39f724e2-15bf-4f35-b560-9d0d15606462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the grid DataFrames\n",
    "def create_grid_dataframes():\n",
    "    azimuth_map, elevation_map = create_mappings()\n",
    "    grid_shape = (len(elevation_map), len(azimuth_map))\n",
    "    df_heights = pd.DataFrame({key: [[] for _ in range(len(elevation_map))] \\\n",
    "                                 for key in azimuth_map.keys()}, index=elevation_map.keys())\n",
    "    return df_heights, azimuth_map, elevation_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "87791ed8-709c-43ec-808f-a7f735d6cf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process file into grid\n",
    "def process_files_to_grid(data_dir):\n",
    "    # Create empty grid\n",
    "    df_heights, azimuth_map, elevation_map = create_grid_dataframes()\n",
    "\n",
    "    lidar_dir = Path(data_dir, 'velodyne_points')\n",
    "    # For each file in the directory\n",
    "    for file_path in lidar_dir.iterdir():\n",
    "    # for file_path in itertools.islice(lidar_dir.iterdir(), 3):\n",
    "        print('.', end='')\n",
    "        data = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)\n",
    "        for x, y, z, intensity in data:\n",
    "            # Convert to azimuth, height, distance format\n",
    "            # distance = np.sqrt(x**2 + y**2 + z**2)\n",
    "            azimuth = np.degrees(np.arctan2(y, x))\n",
    "            elevation = np.degrees(np.arctan2(z, np.sqrt(x**2 + y**2)))\n",
    "            # Convert and scale\n",
    "            azimuth_idx = (np.floor((azimuth + 180) / azimuth_resolution) * azimuth_resolution * 10 - 1800).astype(int)\n",
    "            elevation_idx = (np.floor((elevation + 30) / elevation_resolution) * elevation_resolution * 10 - 300).astype(int)\n",
    "            # Update DataFrames directly using indices\n",
    "            if azimuth_idx in azimuth_map and elevation_idx in elevation_map:\n",
    "                df_heights.at[elevation_idx, azimuth_idx].append(z)\n",
    "    return df_heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e27c9a29-1f32-447a-b08f-0dcf82274fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_background_lookup_table(dir):\n",
    "    # Get the distances of the background map from the lidar files\n",
    "    df_heights = process_files_to_grid(dir)\n",
    "\n",
    "    # Create a new DataFrame with the same index and columns as df_distances\n",
    "    lookup_table = pd.DataFrame(index=df_heights.index, columns=df_heights.columns)\n",
    "    # Iterate through each cell in df_distances\n",
    "    for (elevation, azimuth), z in df_heights.stack().items():\n",
    "        if z:  # If the list is not empty\n",
    "            if np.average(z) < 0:\n",
    "                value = np.percentile(z, 25)\n",
    "            else:\n",
    "                value = np.percentile(z, 75)\n",
    "        else:\n",
    "            value = np.nan  # If the list is empty, set the cell to NaN\n",
    "\n",
    "        # Set the value in the new DataFrame\n",
    "        lookup_table.at[elevation, azimuth] = value\n",
    "\n",
    "    filled_lookup_table = lookup_table.ffill(axis=0).bfill(axis=0)  # Fill along rows\n",
    "    filled_lookup_table = filled_lookup_table.ffill(axis=1).bfill(axis=1)\n",
    "\n",
    "    return filled_lookup_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6231c973-5d7e-476e-9fc5-44c09d4ef27c",
   "metadata": {},
   "source": [
    "## Filtering and saving functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "af930e13-e6a1-43ce-86e0-666e9f94801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dataframe(bin_path):\n",
    "    pre_filtered_data = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4) \n",
    "    columns = ['x', 'y', 'z', 'intensity']\n",
    "    df = pd.DataFrame(pre_filtered_data, columns=columns)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b95c4d38-7e51-4d13-8b98-8c683e7ba7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lookup_coords_to_xyz(points_df):\n",
    "    # Calculate the distance, azimuth, and height using vectorized operations\n",
    "    x, y, z, intensity = points_df['x'], points_df['y'], points_df['z'], points_df['intensity']\n",
    "    azimuth = np.degrees(np.arctan2(y, x))\n",
    "    elevation = np.degrees(np.arctan2(z, np.sqrt(x**2 + y**2)))\n",
    "    \n",
    "    # Convert and scale\n",
    "    azimuth_idx = (np.floor((azimuth + 180) / azimuth_resolution) * azimuth_resolution * 10 - 1800).astype(int)\n",
    "    elevation_idx = (np.floor((elevation + 30) / elevation_resolution) * elevation_resolution * 10 - 300).astype(int)\n",
    "    \n",
    "    # Add new columns to dataframe\n",
    "    points_df['azimuth_idx'] = azimuth_idx\n",
    "    points_df['elevation_idx'] = elevation_idx\n",
    "    points_df['delta_z'] = elevation / 55\n",
    "    \n",
    "    return points_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "488d3c76-e60d-4011-9b58-ce05ec7aded6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def filter_points(input_file, lookup_table):\n",
    "#     # Get dataframe from file\n",
    "#     pre_filtered_points = convert_to_dataframe(input_file)\n",
    "\n",
    "#     # Add lookup table coordinates\n",
    "#     pre_filtered_grid_lookup = add_lookup_coords_to_xyz(pre_filtered_points)\n",
    "    \n",
    "#     # Initialize a list to store rows that meet the criteria\n",
    "#     filtered_data = []\n",
    "\n",
    "#     # Iterate through each row in the input DataFrame\n",
    "#     # for idx, row in df_input.iloc[:10].iterrows():\n",
    "#     for idx, row in pre_filtered_grid_lookup.iterrows():\n",
    "#         azimuth_idx = int(row['azimuth_idx'])\n",
    "#         height_idx = int(row['height_idx'])\n",
    "        \n",
    "#         # Check if the indices exist in the lookup table and the value is not NaN\n",
    "#         if azimuth_idx in lookup_table.columns and height_idx in lookup_table.index:\n",
    "#             # print('.', end='')\n",
    "#             lookup_value = lookup_table.at[height_idx, azimuth_idx]\n",
    "            \n",
    "#             if not pd.isna(lookup_value) and row['distance'] < lookup_value:\n",
    "#                 # If criteria are met, add the row's x, y, z, and intensity to the filtered_data list\n",
    "#                 filtered_data.append({\n",
    "#                     'x': row['x'],\n",
    "#                     'y': row['y'],\n",
    "#                     'z': row['z'],\n",
    "#                     'intensity': row['intensity']\n",
    "#                 })\n",
    "\n",
    "#     # Create a DataFrame from the filtered data\n",
    "#     filtered_df = pd.DataFrame(filtered_data)\n",
    "#     return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e3cba263-acc4-4d32-8320-21ddeb0e7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_points(frame_path, lookup_table):\n",
    "    pre_filtered_points = convert_to_dataframe(frame_path)\n",
    "    pre_filtered_grid_lookup = add_lookup_coords_to_xyz(pre_filtered_points)\n",
    "    \n",
    "    # Convert 'azimuth_idx' and 'height_idx' to integers\n",
    "    pre_filtered_grid_lookup['azimuth_idx'] = pre_filtered_grid_lookup['azimuth_idx'].astype(int)\n",
    "    pre_filtered_grid_lookup['elevation_idx'] = pre_filtered_grid_lookup['elevation_idx'].astype(int)\n",
    "\n",
    "    # Set index to ['height_idx', 'azimuth_idx'] for alignment with lookup_table\n",
    "    pre_filtered_grid_lookup.set_index(['elevation_idx', 'azimuth_idx'], inplace=True)\n",
    "    \n",
    "    # Flatten the lookup_table into a series with MultiIndex from its row and column indices\n",
    "    lookup_series = lookup_table.stack()\n",
    "\n",
    "    # Reindex the lookup values to align with the pre_filtered_grid_lookup index\n",
    "    lookup_values = lookup_series.reindex(pre_filtered_grid_lookup.index)\n",
    "\n",
    "    # Compute effective heights and absolute comparison within the DataFrame\n",
    "    pre_filtered_grid_lookup['effective_height'] = abs(pre_filtered_grid_lookup['z'] + pre_filtered_grid_lookup['delta_z'])\n",
    "    pre_filtered_grid_lookup['bg_height'] = lookup_values\n",
    "\n",
    "    # Filter based on condition: check where effective height is less than the background height\n",
    "    filtered_df = pre_filtered_grid_lookup[pre_filtered_grid_lookup['effective_height'] < abs(pre_filtered_grid_lookup['bg_height'])]\n",
    "\n",
    "    # Reset index if you want 'height_idx' and 'azimuth_idx' as columns\n",
    "    filtered_df = filtered_df.reset_index()\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e77a6403-4e34-45d3-8ae4-f3ca96710410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_binary(df, bin_path):\n",
    "    # Ensure the DataFrame is in the correct order and data type\n",
    "    data = df[['x', 'y', 'z', 'intensity']].astype(np.float32).values\n",
    "    \n",
    "    # Write the data to a binary file\n",
    "    data.tofile(bin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f742807-8599-44f8-a52e-7b5b14f12cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_frames(dir, background_lookup_table):\n",
    "    # Create a new folder for the filtered frames in the directory\n",
    "    new_save_location = Path(dir, 'filtered_points')\n",
    "    new_save_location.mkdir(exist_ok=True)\n",
    "    \n",
    "    lidar_dir = Path(dir, 'velodyne_points')\n",
    "    \n",
    "    # Get just the file names\n",
    "    files = [f for f in os.listdir(lidar_dir) if f.endswith('.bin')]\n",
    "    # For each file\n",
    "    # for filename in files[:3]:\n",
    "    for filename in files:\n",
    "        # Append file name to location\n",
    "        print(filename, end=', ')\n",
    "        from_file = Path(lidar_dir, filename)\n",
    "\n",
    "        # Filter file\n",
    "        filtered_df = filter_points(from_file, background_lookup_table)\n",
    "\n",
    "        # APPEND FILE NAME TO NEW LOCATION\n",
    "        to_file = Path(new_save_location, filename)\n",
    "\n",
    "        # CONVERT BACK TO BINARY and save\n",
    "        save_as_binary(filtered_df, to_file)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "639cb573-5c95-4d31-aa22-862a1b2a4077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\stationary_data\\2011_09_26_drive_0017_sync_0_to_113\n",
      "...0000000000.bin, 0000000001.bin, 0000000002.bin, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilya\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "C:\\Users\\gilya\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "C:\\Users\\gilya\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "..\\stationary_data\\2011_09_26_drive_0018_sync_0_to_178\n",
      "...0000000000.bin, 0000000001.bin, 0000000002.bin, \n",
      "..\\stationary_data\\2011_09_26_drive_0051_sync_210_to_210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gilya\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "C:\\Users\\gilya\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n",
      "C:\\Users\\gilya\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73: RuntimeWarning: invalid value encountered in less\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdir\u001b[39m) \n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Make background map\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m background_distance_lookup_table \u001b[38;5;241m=\u001b[39m create_background_lookup_table(\u001b[38;5;28mdir\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Filter and save each filtered frame\u001b[39;00m\n\u001b[0;32m     11\u001b[0m filter_frames(\u001b[38;5;28mdir\u001b[39m, background_distance_lookup_table)\n",
      "Cell \u001b[1;32mIn[78], line 11\u001b[0m, in \u001b[0;36mcreate_background_lookup_table\u001b[1;34m(dir)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m z:  \u001b[38;5;66;03m# If the list is not empty\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39maverage(z) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m         value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(z, \u001b[38;5;241m25\u001b[39m)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m         value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpercentile(z, \u001b[38;5;241m75\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4283\u001b[0m, in \u001b[0;36mpercentile\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims, interpolation)\u001b[0m\n\u001b[0;32m   4281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _quantile_is_valid(q):\n\u001b[0;32m   4282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPercentiles must be in the range [0, 100]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 4283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _quantile_unchecked(\n\u001b[0;32m   4284\u001b[0m     a, q, axis, out, overwrite_input, method, keepdims)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4555\u001b[0m, in \u001b[0;36m_quantile_unchecked\u001b[1;34m(a, q, axis, out, overwrite_input, method, keepdims)\u001b[0m\n\u001b[0;32m   4547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_quantile_unchecked\u001b[39m(a,\n\u001b[0;32m   4548\u001b[0m                         q,\n\u001b[0;32m   4549\u001b[0m                         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4552\u001b[0m                         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4553\u001b[0m                         keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   4554\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[1;32m-> 4555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ureduce(a,\n\u001b[0;32m   4556\u001b[0m                     func\u001b[38;5;241m=\u001b[39m_quantile_ureduce_func,\n\u001b[0;32m   4557\u001b[0m                     q\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   4558\u001b[0m                     keepdims\u001b[38;5;241m=\u001b[39mkeepdims,\n\u001b[0;32m   4559\u001b[0m                     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   4560\u001b[0m                     out\u001b[38;5;241m=\u001b[39mout,\n\u001b[0;32m   4561\u001b[0m                     overwrite_input\u001b[38;5;241m=\u001b[39moverwrite_input,\n\u001b[0;32m   4562\u001b[0m                     method\u001b[38;5;241m=\u001b[39mmethod)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:3823\u001b[0m, in \u001b[0;36m_ureduce\u001b[1;34m(a, func, keepdims, **kwargs)\u001b[0m\n\u001b[0;32m   3820\u001b[0m             index_out \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;241m*\u001b[39m nd\n\u001b[0;32m   3821\u001b[0m             kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m out[(\u001b[38;5;28mEllipsis\u001b[39m, ) \u001b[38;5;241m+\u001b[39m index_out]\n\u001b[1;32m-> 3823\u001b[0m r \u001b[38;5;241m=\u001b[39m func(a, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4722\u001b[0m, in \u001b[0;36m_quantile_ureduce_func\u001b[1;34m(a, q, axis, out, overwrite_input, method)\u001b[0m\n\u001b[0;32m   4720\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4721\u001b[0m         arr \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m-> 4722\u001b[0m result \u001b[38;5;241m=\u001b[39m _quantile(arr,\n\u001b[0;32m   4723\u001b[0m                    quantiles\u001b[38;5;241m=\u001b[39mq,\n\u001b[0;32m   4724\u001b[0m                    axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   4725\u001b[0m                    method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   4726\u001b[0m                    out\u001b[38;5;241m=\u001b[39mout)\n\u001b[0;32m   4727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\function_base.py:4825\u001b[0m, in \u001b[0;36m_quantile\u001b[1;34m(arr, quantiles, axis, method, out)\u001b[0m\n\u001b[0;32m   4820\u001b[0m previous_indexes, next_indexes \u001b[38;5;241m=\u001b[39m _get_indexes(arr,\n\u001b[0;32m   4821\u001b[0m                                               virtual_indexes,\n\u001b[0;32m   4822\u001b[0m                                               values_count)\n\u001b[0;32m   4823\u001b[0m \u001b[38;5;66;03m# --- Sorting\u001b[39;00m\n\u001b[0;32m   4824\u001b[0m arr\u001b[38;5;241m.\u001b[39mpartition(\n\u001b[1;32m-> 4825\u001b[0m     np\u001b[38;5;241m.\u001b[39munique(np\u001b[38;5;241m.\u001b[39mconcatenate(([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m   4826\u001b[0m                               previous_indexes\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[0;32m   4827\u001b[0m                               next_indexes\u001b[38;5;241m.\u001b[39mravel(),\n\u001b[0;32m   4828\u001b[0m                               ))),\n\u001b[0;32m   4829\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   4830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m supports_nans:\n\u001b[0;32m   4831\u001b[0m     slices_having_nans \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misnan(arr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:276\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[38;5;241m=\u001b[39mequal_nan)\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:125\u001b[0m, in \u001b[0;36m_unpack_tuple\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    121\u001b[0m     np\u001b[38;5;241m.\u001b[39msubtract(ary[\u001b[38;5;241m1\u001b[39m:], ary[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], result[l_begin:l_begin \u001b[38;5;241m+\u001b[39m l_diff])\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unpack_tuple\u001b[39m(x):\n\u001b[0;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Unpacks one-element tuples for use as return values \"\"\"\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# For each folder in the stationary data directory\n",
    "p = Path(DATA_DIR_ROOT)\n",
    "\n",
    "# For each sequence (folder) in the stationary data\n",
    "for dir in p.iterdir(): \n",
    "    if dir.is_dir():\n",
    "        print(dir) \n",
    "        # Make background map\n",
    "        background_distance_lookup_table = create_background_lookup_table(dir)\n",
    "        # Filter and save each filtered frame\n",
    "        filter_frames(dir, background_distance_lookup_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
